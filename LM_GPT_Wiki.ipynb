{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "698eae6f-b527-446a-bf7e-784bb4734e6f",
   "metadata": {},
   "source": [
    "# Supervised Fine Tuning with GPT-Like Transformer\n",
    "## Language Modelling with Dump of Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa7481a-f584-4076-9ba7-c5584bac6434",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "#plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.figsize'] = (4, 2)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from models.transformer import GPT\n",
    "\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'USING DEVICE: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450fdd01-c440-441b-8924-9a18be5f9a95",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a2b0be-b2c1-40e4-8e48-be1ac86a0608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "sentiment_nano = {\n",
    "    'features_dim': 64, \n",
    "    'num_heads': 8,\n",
    "    'num_encoder_layers': 2,\n",
    "    'num_decoder_layers': -1,\n",
    "    #'ff_dim': 64 * 4,\n",
    "    'ff_dim': 64 // 16,\n",
    "    'emb_dropout_prob': 0.1,\n",
    "    'attn_dropout_prob': 0.0,\n",
    "    'ff_dropout_prob': 0.1,\n",
    "    'attn_use_bias': False,\n",
    "    'ff_use_bias': False,\n",
    "}\n",
    "\n",
    "gpt_small = {\n",
    "    'vocab_size': 50_257,\n",
    "    'features_dim': 384, \n",
    "    'num_heads': 6,\n",
    "    #'ff_dim': 64 * 4,\n",
    "    'ff_dim': 384, # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    'num_decoder_layers': 6,\n",
    "    'emb_dropout_prob': 0.1,\n",
    "    'attn_dropout_prob': 0.0,\n",
    "    'ff_dropout_prob': 0.1,\n",
    "    'attn_use_bias': False,  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    'ff_use_bias': False,  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    'vocab_projection_bias': True\n",
    "}\n",
    "\n",
    "\n",
    "steplr = {\n",
    "    'type': 'StepLR',\n",
    "    #'step_size': 2,\n",
    "    'step_size': 800,\n",
    "    #'gamma': 0.80,\n",
    "    'gamma': 0.99,\n",
    "}\n",
    "\n",
    "reduce_lr_on_plateau = {\n",
    "    'type': 'ReduceLROnPlateau',\n",
    "    'mode': 'min',\n",
    "    'factor': 0.1,\n",
    "    'patience': 3,\n",
    "    'cooldown': 0,\n",
    "    'min_lr': 1e-7,\n",
    "}\n",
    "\n",
    "# TODO: revise the max_seq_len and context_size\n",
    "hyperparameters = {\n",
    "    'seed': 99999,\n",
    "    'batch_size': 50,\n",
    "    #'vocab_size': 50_257,\n",
    "    #'max_seq_len': 256, \n",
    "    'context_size': 256,\n",
    "    'split_ratio': 0.75,\n",
    "    'num_epochs': 90,\n",
    "    #'num_training_iters': 5_000,\n",
    "    #'num_validation_iters': 1_000,\n",
    "    'optimizer': {\n",
    "        'learning_rate': 1e-3,\n",
    "        'momentum': 0.9, # SGD\n",
    "        'optimizer_betas': (0.9, 0.999), # Adam, AdamW\n",
    "        'weight_decay': 1e-2, # AdamW\n",
    "    },\n",
    "    'clip_grad_norm': 1.0,\n",
    "    'grad_accum_iter': 4,\n",
    "    'learning_rate_sched_config': reduce_lr_on_plateau,\n",
    "    'dataset_dir': '../data/trwiki-20231120-pages-articles/',\n",
    "    'model_base_name': 'LM_GPTSmall_Wiki_TR',\n",
    "    'model_config': gpt_small,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec3f7d85-ec5b-4803-a89a-27871e7fa515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False # !!!!!!!!!!!!!!!!!!!!!\n",
    "    \n",
    "seed_everything(hyperparameters['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df2dfc8-0068-43e1-b020-11da1d70e1a8",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "* **UPDATED FOR EMOJIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eed5c2a-7a31-4d69-825f-d7d7be210d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess_text = lambda x: re.sub(r'[^\\w\\s]', '', x.lower())\n",
    "preprocess_text = lambda x: x.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee04969b-eadc-436e-832e-16d57e4a8c11",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa09b0bd-5ab7-478a-af02-5c12becc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "500ffea7-6cb4-4c19-a65e-8b545bd54077",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file('/URL/TO/YOUR/TOKENIZER')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae30191-9807-4ac9-9e3c-776ba5e13f68",
   "metadata": {},
   "source": [
    "### Template Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a02873-047a-41d3-b211-ff31521546e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.processors import TemplateProcessing\n",
    "#from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n",
    "#from tokenizers.pre_tokenizers import ByteLevel\n",
    "\n",
    "#tokenizer.pre_tokenizer = ByteLevel()\n",
    "#tokenizer.decoder = ByteLevelDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d437414-67f0-4b6e-8290-99812d82087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = TemplateProcessing(\n",
    "    single='<start> $A <end>',\n",
    "    #pair=\"<start> $A <sep> $B:1 <end>:1\",\n",
    "    special_tokens=[\n",
    "        ('<start>', tokenizer.token_to_id('<start>')),\n",
    "        ('<end>', tokenizer.token_to_id('<end>')),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e681465c-ba25-4e46-b570-76491b43b3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start>', 'Ġmer', 'haba', 'ĠdÃ¼nya', '<end>']\n"
     ]
    }
   ],
   "source": [
    "output = tokenizer.encode('merhaba dünya')\n",
    "print(output.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b53a337-f745-497a-abeb-b4cc46e1e8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.token_to_id('<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20474eb7-5b42-4676-a62b-9f3b559f99d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.token_to_id('<start>'), tokenizer.token_to_id('<end>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14075489-cf99-4d2e-ae49-cbe452400aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encode = lambda s: tokenizer.encode(s).ids # encoder: take a string, output a list of integers\n",
    "decode = lambda t: tokenizer.decode(t, skip_special_tokens=False) # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a26d8aa4-230d-40d1-bcc2-9913661a2e24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> merhaba dünya<end>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(encode('merhaba dünya'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c4e4392-9591-4fc9-b3b3-932b0d95c55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> bugün çok güzel selam dünya<end>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(encode('bugün çok güzel selam dünya'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3abaafc-50e5-45b2-a628-a6619d149e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' merhaba dünya'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode('merhaba dünya').ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fbd41fb-2f55-4976-9381-87486827dfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2992, 42164, 1793, 5]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('merhaba dünya').ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3055f13-09a4-4585-aeec-82827039e2f6",
   "metadata": {},
   "source": [
    "## Vocabulary size from tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fe7ea2b-4696-4106-a192-bfd6814ca17c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0b94bc-ed03-44d3-9da6-2ca9b2bddb5a",
   "metadata": {},
   "source": [
    "## Overwrite existing vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73caafc4-5b0d-4783-9fef-3349b248f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters['model_config']['vocab_size'] = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c52c2a-1d55-4805-b2fe-4161410ffd81",
   "metadata": {},
   "source": [
    "# LM Dataset\n",
    "* NOTE: GIVING UP SOME DATA WHEN LIMITING CONTEXT!\n",
    "* (Tokenizer cutts off some text files)\n",
    "* Text files is passed in as Python list (useful for train/test splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "380e3d5e-ccb1-4f35-b51d-b230a7511646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class Wiki_TR(Dataset):\n",
    "    def __init__(self, root_dir, dataset_files_list, tokenizer, context_size):\n",
    "        self.root_dir = root_dir\n",
    "        self.dataset_files_list = dataset_files_list\n",
    "        self.tokenizer = tokenizer\n",
    "        self.context_size = context_size\n",
    "\n",
    "        self.file_paths = [os.path.join(root_dir, file) for file in dataset_files_list if not 'combined' in file]\n",
    "        self.total_files = len(self.file_paths)\n",
    "\n",
    "        # NOTE: GIVING UP SOME DATA WHEN LIMITING CONTEXT!\n",
    "        # (Tokenizer cutts off some text files)\n",
    "        self.tokenizer.enable_padding(length=context_size)\n",
    "        self.tokenizer.enable_truncation(max_length=context_size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.total_files\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #sample = self.file_paths[idx]\n",
    "        with open(self.file_paths[idx], 'r') as f:\n",
    "            sample = f.read()\n",
    "\n",
    "        #######################################\n",
    "        '''\n",
    "        _high = len(sample)-self.context_size\n",
    "        \n",
    "        if _high > 0:\n",
    "            offset = random.randint(0, _high)\n",
    "            sample = sample[offset:]\n",
    "        '''\n",
    "        #######################################\n",
    "                \n",
    "        _encoded = self.tokenizer.encode(sample)\n",
    "\n",
    "        input_token_ids = torch.tensor(_encoded.ids[:-1], dtype=torch.long)\n",
    "        attention_mask = torch.tensor(_encoded.attention_mask[:-1], dtype=torch.float32)\n",
    "        target_token_ids = torch.tensor(_encoded.ids[1:], dtype=torch.long)\n",
    "        \n",
    "        input_token_ids, attention_mask, target_token_ids\n",
    "        \n",
    "        return input_token_ids, attention_mask, target_token_ids\n",
    "\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f56426-5878-4e5c-9654-a1f0a26ffad3",
   "metadata": {},
   "source": [
    "### Cached Implementation\n",
    "* Continuous stream of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d17b5d94-cd4e-4700-862f-0178f300128b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass Wiki_TR_Cached(Dataset):\\n    def __init__(self, tokenized_cached_corpus, context_size, start_token_id, end_token_id, start_offset=0, mode=\\'single-step\\'):\\n        self.tokenized_cached_corpus = tokenized_cached_corpus\\n        self.context_size = context_size\\n        self.start_token = torch.tensor([start_token_id], dtype=torch.long)\\n        self.end_token = torch.tensor([end_token_id], dtype=torch.long)\\n        self.start_offset = start_offset\\n        self.mode = mode\\n\\n        # TODO: implement context-step and random\\n        self.available_modes = [\\n            \\'single-step\\',\\n            \\'context-step\\',\\n            \\'random\\'\\n        ]\\n\\n        if mode not in self.available_modes:\\n            raise NotImplementedError(f\\'Mode {mode} is not valid! Valid options are: {self.available_modes}\\')\\n    \\n    def generate_context(self, tokens, context_size, offset):\\n        #offset = torch.randint(low=0, high=len(tokens)-context_size, size=(1,))\\n        #print(f\\'offset\\', offset)\\n    \\n        start_token = self.start_token\\n        end_token = self.end_token\\n    \\n        selected_context_temp = tokens[offset:offset+context_size]\\n        \\n        #print(selected_context_temp[0], selected_context_temp[-1])\\n\\n        \"\"\"\\n        if selected_context_temp[0] == start_token and selected_context_temp[-1] == end_token:\\n        \\n            selected_context = tokens[offset:offset+context_size]\\n        \\n        elif selected_context_temp[0] == start_token and selected_context_temp[-1] != end_token:\\n            \\n            selected_context = tokens[offset:offset-1+context_size]\\n            selected_context = torch.cat((selected_context, end_token))\\n    \\n        elif selected_context_temp[0] != start_token and selected_context_temp[-1] == end_token:\\n            \\n            selected_context = tokens[offset+1:offset+context_size]\\n            selected_context = torch.cat((start_token, selected_context))\\n        \\n        elif selected_context_temp[0] != start_token and selected_context_temp[-1] != end_token:\\n            \\n            selected_context = tokens[offset+1:offset-1+context_size]\\n            selected_context = torch.cat((start_token, selected_context, end_token))\\n        \"\"\"\\n\\n        return selected_context_temp\\n        #return selected_context\\n\\n    \\n    def __len__(self):\\n        return (len(self.tokenized_cached_corpus) - self.context_size)//self.context_size\\n    \\n    def __getitem__(self, idx):\\n        \"\"\"\\n        #sample = self.file_paths[idx]\\n        with open(self.file_paths[idx], \\'r\\') as f:\\n            sample = f.read()\\n\\n        #######################################\\n        _high = len(sample)-self.context_size\\n        \\n        if _high > 0:\\n            offset = random.randint(0, _high)\\n            sample = sample[offset:]\\n        #######################################\\n                \\n        _encoded = self.tokenizer.encode(sample)\\n\\n        input_token_ids = torch.tensor(_encoded.ids[:-1], dtype=torch.long)\\n        attention_mask = torch.tensor(_encoded.attention_mask[:-1], dtype=torch.float32)\\n        target_token_ids = torch.tensor(_encoded.ids[1:], dtype=torch.long)\\n        \\n        input_token_ids, attention_mask, target_token_ids\\n        \"\"\"\\n\\n        context = self.generate_context(self.tokenized_cached_corpus, self.context_size, (idx*self.context_size)+self.start_offset)\\n        #context = self.generate_context(self.tokenized_cached_corpus, self.context_size, idx+self.start_offset)\\n\\n        input_token_ids = context[:-1]\\n        attention_mask = torch.ones_like(input_token_ids, dtype=torch.float32)\\n        target_token_ids = context[1:]\\n        \\n        return input_token_ids, attention_mask, target_token_ids\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class Wiki_TR_Cached(Dataset):\n",
    "    def __init__(self, tokenized_cached_corpus, context_size, start_token_id, end_token_id, start_offset=0, mode='single-step'):\n",
    "        self.tokenized_cached_corpus = tokenized_cached_corpus\n",
    "        self.context_size = context_size\n",
    "        self.start_token = torch.tensor([start_token_id], dtype=torch.long)\n",
    "        self.end_token = torch.tensor([end_token_id], dtype=torch.long)\n",
    "        self.start_offset = start_offset\n",
    "        self.mode = mode\n",
    "\n",
    "        # TODO: implement context-step and random\n",
    "        self.available_modes = [\n",
    "            'single-step',\n",
    "            'context-step',\n",
    "            'random'\n",
    "        ]\n",
    "\n",
    "        if mode not in self.available_modes:\n",
    "            raise NotImplementedError(f'Mode {mode} is not valid! Valid options are: {self.available_modes}')\n",
    "    \n",
    "    def generate_context(self, tokens, context_size, offset):\n",
    "        #offset = torch.randint(low=0, high=len(tokens)-context_size, size=(1,))\n",
    "        #print(f'offset', offset)\n",
    "    \n",
    "        start_token = self.start_token\n",
    "        end_token = self.end_token\n",
    "    \n",
    "        selected_context_temp = tokens[offset:offset+context_size]\n",
    "        \n",
    "        #print(selected_context_temp[0], selected_context_temp[-1])\n",
    "\n",
    "        \"\"\"\n",
    "        if selected_context_temp[0] == start_token and selected_context_temp[-1] == end_token:\n",
    "        \n",
    "            selected_context = tokens[offset:offset+context_size]\n",
    "        \n",
    "        elif selected_context_temp[0] == start_token and selected_context_temp[-1] != end_token:\n",
    "            \n",
    "            selected_context = tokens[offset:offset-1+context_size]\n",
    "            selected_context = torch.cat((selected_context, end_token))\n",
    "    \n",
    "        elif selected_context_temp[0] != start_token and selected_context_temp[-1] == end_token:\n",
    "            \n",
    "            selected_context = tokens[offset+1:offset+context_size]\n",
    "            selected_context = torch.cat((start_token, selected_context))\n",
    "        \n",
    "        elif selected_context_temp[0] != start_token and selected_context_temp[-1] != end_token:\n",
    "            \n",
    "            selected_context = tokens[offset+1:offset-1+context_size]\n",
    "            selected_context = torch.cat((start_token, selected_context, end_token))\n",
    "        \"\"\"\n",
    "\n",
    "        return selected_context_temp\n",
    "        #return selected_context\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.tokenized_cached_corpus) - self.context_size)//self.context_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        #sample = self.file_paths[idx]\n",
    "        with open(self.file_paths[idx], 'r') as f:\n",
    "            sample = f.read()\n",
    "\n",
    "        #######################################\n",
    "        _high = len(sample)-self.context_size\n",
    "        \n",
    "        if _high > 0:\n",
    "            offset = random.randint(0, _high)\n",
    "            sample = sample[offset:]\n",
    "        #######################################\n",
    "                \n",
    "        _encoded = self.tokenizer.encode(sample)\n",
    "\n",
    "        input_token_ids = torch.tensor(_encoded.ids[:-1], dtype=torch.long)\n",
    "        attention_mask = torch.tensor(_encoded.attention_mask[:-1], dtype=torch.float32)\n",
    "        target_token_ids = torch.tensor(_encoded.ids[1:], dtype=torch.long)\n",
    "        \n",
    "        input_token_ids, attention_mask, target_token_ids\n",
    "        \"\"\"\n",
    "\n",
    "        context = self.generate_context(self.tokenized_cached_corpus, self.context_size, (idx*self.context_size)+self.start_offset)\n",
    "        #context = self.generate_context(self.tokenized_cached_corpus, self.context_size, idx+self.start_offset)\n",
    "\n",
    "        input_token_ids = context[:-1]\n",
    "        attention_mask = torch.ones_like(input_token_ids, dtype=torch.float32)\n",
    "        target_token_ids = context[1:]\n",
    "        \n",
    "        return input_token_ids, attention_mask, target_token_ids\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3306b75a-5200-4292-97b9-4ca5430ed74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = list(range(10))\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5d71fa9-ace6-4962-8da9-2f69bbb5a3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01418f65-a6c1-431a-99b6-0352161803ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4cb0a-448f-4337-b39d-295a6da152f9",
   "metadata": {},
   "source": [
    "### Full List of Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d9871ff-8451-4f43-97b5-094c5365ca2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original len: 423135\n",
      "downsampled len: 105783\n"
     ]
    }
   ],
   "source": [
    "full_text_files_list = os.listdir(hyperparameters['dataset_dir'])\n",
    "print(f'original len: {len(full_text_files_list)}')\n",
    "\n",
    "# downsample dataset for faster training times\n",
    "full_text_files_list = full_text_files_list[:len(full_text_files_list)//4]\n",
    "\n",
    "print(f'downsampled len: {len(full_text_files_list)}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4266038c-1475-4c14-8129-b75ab71eb9c3",
   "metadata": {},
   "source": [
    "cached_file_path = 'trwiki-20231120-pages-articles_cached.pkl'\n",
    "\n",
    "with open(cached_file_path, 'rb') as file:\n",
    "    tokenized_cached_corpus = pickle.load(file)\n",
    "\n",
    "cached_tokens = torch.tensor(tokenized_cached_corpus, dtype=torch.long)\n",
    "\n",
    "print(f'{len(tokenized_cached_corpus):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ebaca1f-fa78-4c0d-8909-161a4b843792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105783"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ds = Wiki_TR(\n",
    "    root_dir=hyperparameters['dataset_dir'],\n",
    "    dataset_files_list=full_text_files_list, \n",
    "    tokenizer=tokenizer,\n",
    "    context_size=hyperparameters['context_size']\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "full_ds = Wiki_TR_Cached(\n",
    "    tokenized_cached_corpus=cached_tokens,\n",
    "    context_size=hyperparameters['context_size'],\n",
    "    start_token_id=tokenizer.token_to_id('<start>'),\n",
    "    end_token_id=tokenizer.token_to_id('<end>'),\n",
    "    start_offset=0,\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "len(full_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "154d089d-3d9c-4442-b5d7-0842ca70b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_input_token_ids, ex_attention_mask, ex_target_token_ids = full_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c95d752-ccf3-44ed-b39d-c590a6d2d2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<start> Cengiz Han (doğum adıyla Temuçin,  – 18 Ağustos 1227), Moğol İmparatorluğu'nun kurucusu ve ilk Kağanı olan Moğol komutan ve [kaynağı | url = https://www.britannica.com/biography/Genghis-Khan | başlık = Genghis Khan; Mongol Ruler | erişimtarihi = 12 Eylül 2020 | tarih =  | çalışma =  | yayıncı = Encyclopædia Britannica | arşivurl = https://web.archive.org/web/20150618194658/https://www.britannica.com/biography/Genghis-Khan | arşivtarihi = 18 Haziran 2015 | ölüurl = hayır }} Hükümdarlığı döneminde gerçekleştirdiği hiçbir savaşı kaybetmeyen Cengiz Han, dünya tarihinin en büyük askeri liderlerinden birisi olarak kabul edilmektedir. \\n<end><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(ex_input_token_ids.tolist()))\n",
    "decode(ex_input_token_ids.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dad0c408-08b2-491f-93c7-77a0d3686d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Cengiz Han (doğum adıyla Temuçin,  – 18 Ağustos 1227), Moğol İmparatorluğu'nun kurucusu ve ilk Kağanı olan Moğol komutan ve [kaynağı | url = https://www.britannica.com/biography/Genghis-Khan | başlık = Genghis Khan; Mongol Ruler | erişimtarihi = 12 Eylül 2020 | tarih =  | çalışma =  | yayıncı = Encyclopædia Britannica | arşivurl = https://web.archive.org/web/20150618194658/https://www.britannica.com/biography/Genghis-Khan | arşivtarihi = 18 Haziran 2015 | ölüurl = hayır }} Hükümdarlığı döneminde gerçekleştirdiği hiçbir savaşı kaybetmeyen Cengiz Han, dünya tarihinin en büyük askeri liderlerinden birisi olarak kabul edilmektedir. \\n<end><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(ex_target_token_ids.tolist()))\n",
    "decode(ex_target_token_ids.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecae4070-3fe7-4930-a9f7-8f1aadf000f2",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca4fa798-87da-41ca-9753-18620ead3dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full: 105783, train: 79337, test: 26446, (combined: 105783)\n"
     ]
    }
   ],
   "source": [
    "train_size = round(len(full_ds) * hyperparameters['split_ratio'])\n",
    "test_size = len(full_ds) - train_size\n",
    "\n",
    "print(f'Full: {len(full_ds)}, train: {train_size}, test: {test_size}, (combined: {train_size+test_size})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e87f342-b876-40e5-a1f5-88bc9748c73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = list(range(20))\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18db26ed-ab41-4b5e-95a3-83e1970b38a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abac43f1-50ec-42d5-8b98-5660b6f803f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2[15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "924f7d02-5bfb-44d4-b2a4-565bd49a869d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79337, 26446)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, test_dataset = random_split(full_ds, [train_size, test_size])\n",
    "\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e8671ef-ec85-4ede-b4c4-1a191388e004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> Ásmundur Sveinsson (20 Mayıs 1893, Kolsstadir, Batı İzlanda - 9 Aralık 1982, Reykjavik), İzlandalı heykeltıraş. \n",
      "1915 yılında Ásmundur Reykjavík'e taşındı ve İzlanda Teknik Okulu'na yazıldı. Orada, heykeltıraş Ríkarður Jónsson yönetiminde çıraklık eğitimi aldı. 1919'da Kopenhag, oradan Stokholm'e, Güzel Sanatlar Akademisi'nde heykeltıraş Carl Milles'le altı sene eğitim görmek üzere taşındı. \n",
      "1924'te heykeltıraş Gunnfríður Jónsdóttir'le evlendi. Eşiyle boşandıktan sonra İngrid adında bir kadınla evlendi ve ondan iki çocuğu oldu. Akademi'den mezun olduktan sonra Ásmundur Paris'e eğitimine devam etmek için taşındı ve orada heykeltıraş Charles Despiau'yla çalıştı. \n",
      "Ásmundur 1929'da İzlanda'ya dönerdönmez soyut, figüratif çalışmalar yapmaya başladı. Temaları daha çok çalışan kadın ve erkeklerdi - The Blacksmith, The Washer Women ve The Water Carrier eserlerinde olduğu gibi. \n",
      "1940'larda başlangıç noktası insan ve hayvanlar olan Ásmundur'un çalışmaları 1950'lere gelindiğinde farklılık gösterdi ve formları neredeyse soyut hâli aldı. \n",
      "\n",
      "********************\n",
      " Ásmundur Sveinsson (20 Mayıs 1893, Kolsstadir, Batı İzlanda - 9 Aralık 1982, Reykjavik), İzlandalı heykeltıraş. \n",
      "1915 yılında Ásmundur Reykjavík'e taşındı ve İzlanda Teknik Okulu'na yazıldı. Orada, heykeltıraş Ríkarður Jónsson yönetiminde çıraklık eğitimi aldı. 1919'da Kopenhag, oradan Stokholm'e, Güzel Sanatlar Akademisi'nde heykeltıraş Carl Milles'le altı sene eğitim görmek üzere taşındı. \n",
      "1924'te heykeltıraş Gunnfríður Jónsdóttir'le evlendi. Eşiyle boşandıktan sonra İngrid adında bir kadınla evlendi ve ondan iki çocuğu oldu. Akademi'den mezun olduktan sonra Ásmundur Paris'e eğitimine devam etmek için taşındı ve orada heykeltıraş Charles Despiau'yla çalıştı. \n",
      "Ásmundur 1929'da İzlanda'ya dönerdönmez soyut, figüratif çalışmalar yapmaya başladı. Temaları daha çok çalışan kadın ve erkeklerdi - The Blacksmith, The Washer Women ve The Water Carrier eserlerinde olduğu gibi. \n",
      "1940'larda başlangıç noktası insan ve hayvanlar olan Ásmundur'un çalışmaları 1950'lere gelindiğinde farklılık gösterdi ve formları neredeyse soyut hâli aldı. \n",
      "<end>\n"
     ]
    }
   ],
   "source": [
    "ex_input_token_ids, ex_attention_mask, ex_target_token_ids = train_dataset[0]\n",
    "print(decode(ex_input_token_ids.tolist()))\n",
    "print('*'*20)\n",
    "print(decode(ex_target_token_ids.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8243f8ce-07ba-43dd-b4ae-b714b69de4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> 1988 Supercopa de España 21 Eylül 1988 ve 29 Eylül 1988 tarihlerinde iki maç olarak oynanan İspanya La Liga şampiyonu olan takım ile Copa del Rey şampiyonu olan takımların aralarında oynadıkları süper kupa karşılaşmasıdır. \n",
      "<end><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "********************\n",
      " 1988 Supercopa de España 21 Eylül 1988 ve 29 Eylül 1988 tarihlerinde iki maç olarak oynanan İspanya La Liga şampiyonu olan takım ile Copa del Rey şampiyonu olan takımların aralarında oynadıkları süper kupa karşılaşmasıdır. \n",
      "<end><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "ex_input_token_ids, ex_attention_mask, ex_target_token_ids = test_dataset[0]\n",
    "print(decode(ex_input_token_ids.tolist()))\n",
    "print('*'*20)\n",
    "print(decode(ex_target_token_ids.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edacee42-7e52-4624-b090-b6e870503add",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "350679de-ef0d-41c8-b223-6a1cc542777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=hyperparameters['batch_size'], \n",
    "    shuffle=True,\n",
    "    #num_workers=1, \n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=hyperparameters['batch_size'], \n",
    "    shuffle=True,\n",
    "    #num_workers=1, \n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5d9e98a-3ebb-4b0c-bc77-59b7f773c44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 255]), torch.Size([50, 255]), torch.Size([50, 255]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i, a, t = next(iter(train_dataloader))\n",
    "i.shape, a.shape, t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15df8b21-2675-4750-8d01-a1cbe5f80b29",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a653394-78b6-44a2-a0b3-5a92614c4111",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 6,989,185\n"
     ]
    }
   ],
   "source": [
    "model = GPT(**hyperparameters['model_config'])\n",
    "\n",
    "print(f'Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "488c75c7-1cd4-4005-9724-517caf874277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_emb parameters: 810,256\n",
      "emb_dropout_prob parameters: 0\n",
      "dec_layers parameters: 5,317,632\n",
      "layernorm_final parameters: 768\n",
      "vocab_projection parameters: 860,529\n"
     ]
    }
   ],
   "source": [
    "for n, m in model.named_children():\n",
    "    print(f'{n} parameters: {sum(p.numel() for p in m.parameters() if p.requires_grad):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40453ac1-b6ef-43cb-9757-8113b2cb159d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 50257])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_batch_size, _seq_len = 1, 20\n",
    "\n",
    "pred = model(torch.randint(low=0, high=hyperparameters['model_config']['vocab_size'], size=(_batch_size, _seq_len)))\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a9236-fad5-4b9b-a34e-37411c75e0d6",
   "metadata": {},
   "source": [
    "# Test input with mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "844d508e-14ee-42af-a3e4-96900b2060e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1.0]*20 for _ in range(_batch_size)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b552fc4b-7ad3-4241-9ad0-b51b505e8786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 50257])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(\n",
    "    x_input=torch.randint(low=0, high=hyperparameters['model_config']['vocab_size'], size=(_batch_size, _seq_len)),\n",
    "    pad_mask=torch.tensor([[1.0]*20 for _ in range(_batch_size)]) # all 1.0\n",
    ")\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0e3125e-01bf-4885-b407-6829357b3955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4326,  0.1047],\n",
       "         [ 0.1812,  0.5329],\n",
       "         [ 0.3142,  0.5814],\n",
       "         [ 0.4007, -1.6001],\n",
       "         [-1.5120, -2.6613]],\n",
       "\n",
       "        [[-0.5496, -0.2339],\n",
       "         [ 1.0727,  1.2074],\n",
       "         [ 1.2624,  0.1069],\n",
       "         [-0.1888,  0.0077],\n",
       "         [ 1.3330, -1.8660]],\n",
       "\n",
       "        [[ 1.5329, -0.3514],\n",
       "         [ 0.3858, -1.2218],\n",
       "         [-1.0494,  0.3704],\n",
       "         [-0.9392, -0.0094],\n",
       "         [-0.3613, -0.1364]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii = torch.randn(3, 5, 2)\n",
    "ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "290f0270-2910-4f9b-80dd-de0a996ab4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 1, 0],\n",
       "        [1, 1, 1, 0, 1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.randint(low=0, high=2, size=(3, 5))\n",
    "print(tt.shape)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b41f975-91e4-4c26-87b4-855fc0b004eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 2])\n",
      "torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "print(ii.view(-1, ii.size(-1)).shape)\n",
    "print(tt.view(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f42b7f5e-742a-4212-8182-02ac9c8a0c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7928)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(ii.view(-1, ii.size(-1)), tt.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fafdda8-8722-428f-a656-d3c3931e70f3",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe42bc-0a67-4709-b490-b6a0bf7910e8",
   "metadata": {},
   "source": [
    "### Without AMP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d9b6653-5566-4201-a129-be8b8faa3d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PBAR_UPDATE_FREQ = 60\n",
    "\n",
    "list_avg = lambda l: sum(l)/len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d96bd3b3-d048-4688-9869-d554c56da144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_iter(dataloader, model, optimizer, criterion, scaler, epoch, clip_grad_norm, pbar_update_freq, device):\n",
    "    model.train()\n",
    "    \n",
    "    #avg_loss = 0.0\n",
    "    avg_loss = []\n",
    "    count = 0\n",
    "\n",
    "    # Accuracy\n",
    "    #acc_correct = 0\n",
    "    #acc_total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, unit=' batch', leave=False)\n",
    "    pbar.set_description(f'Epoch: {epoch}, Train')\n",
    "    \n",
    "    for input_token_ids_batch, attention_mask_batch, target_token_ids_batch in dataloader:\n",
    "\n",
    "        input_token_ids_batch = input_token_ids_batch.to(device)\n",
    "        attention_mask_batch = attention_mask_batch.to(device)\n",
    "        target_token_ids_batch = target_token_ids_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        pred_token_ids_batch = model(\n",
    "            x_input=input_token_ids_batch, \n",
    "            pad_mask=attention_mask_batch\n",
    "        )\n",
    "\n",
    "        # Combine batch and seq_len dims together to form a \"longer batch\"\n",
    "        loss = criterion(\n",
    "            pred_token_ids_batch.view(-1, pred_token_ids_batch.size(-1)),\n",
    "            target_token_ids_batch.view(-1)\n",
    "        )\n",
    "        #loss = criterion(pred_token_ids_batch, target_token_ids_batch)\n",
    "\n",
    "        #avg_loss += loss.item()\n",
    "        avg_loss.append(loss.item())\n",
    "        count += 1\n",
    "\n",
    "        \"\"\"\n",
    "        _, pred_classes = torch.max(pred_token_ids_batch, 1)\n",
    "        acc_correct += (pred_classes == target_token_ids_batch).sum().item()\n",
    "        acc_total += target_token_ids_batch.shape[0]\n",
    "        \"\"\"\n",
    "\n",
    "        if count % pbar_update_freq  == 0:\n",
    "            #iter_accuracy = 100.0 * acc_correct / acc_total\n",
    "            #pbar.set_postfix_str(f'Loss: {list_avg(avg_loss):.4f} Acc: {iter_accuracy:.2f}')\n",
    "            pbar.set_postfix_str(f'Loss: {list_avg(avg_loss):.4f}')\n",
    "            pbar.update(pbar_update_freq)\n",
    "        \n",
    "        loss.backward()\n",
    "        #scaler.scale(loss).backward()\n",
    "        \n",
    "        ### CLIPPING ######\n",
    "        # Prevent exploding gradients with gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "        ###################\n",
    "\n",
    "        optimizer.step()\n",
    "        #optimizer.optimizer.step()\n",
    "        #optimizer.lr_step()\n",
    "        #scaler.step(optimizer.optimizer)\n",
    "        #scaler.update()\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    #final_accuracy = 100.0 * acc_correct / acc_total\n",
    "    #return list_avg(avg_loss), final_accuracy\n",
    "    return list_avg(avg_loss)\n",
    "    \n",
    "@torch.no_grad()\n",
    "def eval_iter(dataloader, model, criterion, epoch, pbar_update_freq, device):\n",
    "    model.eval()\n",
    "    #avg_loss = 0.0\n",
    "    avg_loss = []\n",
    "    count = 0\n",
    "\n",
    "    # Accuracy\n",
    "    #acc_correct = 0\n",
    "    #acc_total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, unit=' batch', leave=False)\n",
    "    pbar.set_description(f'Epoch: {epoch}, Eval')\n",
    "    \n",
    "    for input_token_ids_batch, attention_mask_batch, target_token_ids_batch in dataloader:\n",
    "\n",
    "        input_token_ids_batch = input_token_ids_batch.to(device)\n",
    "        attention_mask_batch = attention_mask_batch.to(device)\n",
    "        target_token_ids_batch = target_token_ids_batch.to(device)\n",
    "\n",
    "        pred_token_ids_batch = model(\n",
    "            x_input=input_token_ids_batch, \n",
    "            pad_mask=attention_mask_batch\n",
    "        )\n",
    "\n",
    "        # Combine batch and seq_len dims together to form a \"longer batch\"\n",
    "        loss = criterion(\n",
    "            pred_token_ids_batch.view(-1, pred_token_ids_batch.size(-1)),\n",
    "            target_token_ids_batch.view(-1)\n",
    "        )\n",
    "        #loss = criterion(pred_token_ids_batch, target_token_ids_batch)\n",
    "            \n",
    "        #avg_loss += loss.item()\n",
    "        avg_loss.append(loss.item())\n",
    "        count += 1\n",
    "        \n",
    "        \"\"\"\n",
    "        _, pred_classes = torch.max(pred_token_ids_batch, 1)\n",
    "        acc_correct += (pred_classes == target_token_ids_batch).sum().item()\n",
    "        acc_total += target_token_ids_batch.shape[0]\n",
    "        \"\"\"\n",
    "\n",
    "        if count % pbar_update_freq  == 0:\n",
    "            #iter_accuracy = 100.0 * acc_correct / acc_total\n",
    "            #pbar.set_postfix_str(f'Loss: {list_avg(avg_loss):.4f} Acc: {iter_accuracy:.2f}')\n",
    "            pbar.set_postfix_str(f'Loss: {list_avg(avg_loss):.4f}')\n",
    "            pbar.update(pbar_update_freq)\n",
    "\n",
    "    pbar.close()\n",
    "    \n",
    "    #final_accuracy = 100.0 * acc_correct / acc_total\n",
    "    #return list_avg(avg_loss), final_accuracy\n",
    "    return list_avg(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb3b29-e0b3-405a-86bd-788be14056bd",
   "metadata": {},
   "source": [
    "### With AMP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9ad8cbec-b1ba-4f52-86e6-d8b6e346be79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_iter_amp(dataloader, model, optimizer, criterion, scaler, epoch, clip_grad_norm, pbar_update_freq, grad_accum_iter, device):\n",
    "    model.train()\n",
    "    \n",
    "    #avg_loss = 0.0\n",
    "    avg_loss = []\n",
    "    count = 0\n",
    "\n",
    "    # Accuracy\n",
    "    #acc_correct = 0\n",
    "    #acc_total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, unit=' batch', leave=False)\n",
    "    pbar.set_description(f'Epoch: {epoch}, Train')\n",
    "        \n",
    "    for batch_idx, (input_token_ids_batch, attention_mask_batch, target_token_ids_batch) in enumerate(dataloader):\n",
    "\n",
    "        input_token_ids_batch = input_token_ids_batch.to(device)\n",
    "        attention_mask_batch = attention_mask_batch.to(device)\n",
    "        target_token_ids_batch = target_token_ids_batch.to(device)\n",
    "\n",
    "        #optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.autocast(device_type=device, dtype=torch.float16, enabled=True):\n",
    "            pred_token_ids_batch = model(\n",
    "                x_input=input_token_ids_batch, \n",
    "                pad_mask=attention_mask_batch\n",
    "            )\n",
    "    \n",
    "            # Combine batch and seq_len dims together to form a \"longer batch\"\n",
    "            loss = criterion(\n",
    "                pred_token_ids_batch.view(-1, pred_token_ids_batch.size(-1)),\n",
    "                target_token_ids_batch.view(-1)\n",
    "            )\n",
    "            #loss = criterion(pred_token_ids_batch, target_token_ids_batch)\n",
    "\n",
    "        #loss.backward()\n",
    "        #scaler.scale(loss).backward()\n",
    "        \n",
    "        ### CLIPPING ######\n",
    "        # Prevent exploding gradients with gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "        ###################\n",
    "\n",
    "        #optimizer.step()\n",
    "        #optimizer.optimizer.step()\n",
    "        #optimizer.lr_step()\n",
    "        #scaler.step(optimizer.optimizer)\n",
    "        #scaler.update()\n",
    "\n",
    "        #optimizer.zero_grad(set_to_none=True) # set_to_none=True here can modestly improve performance\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        ####################\n",
    "        # GRADIENT ACCUMULATION\n",
    "        ####################\n",
    "        if ((batch_idx + 1) % grad_accum_iter == 0) or ((batch_idx + 1) == len(dataloader)):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True) # set_to_none=True here can modestly improve performance\n",
    "        ####################\n",
    "        \n",
    "        #avg_loss += loss.item()\n",
    "        avg_loss.append(loss.item())\n",
    "        count += 1\n",
    "\n",
    "        \"\"\"\n",
    "        _, pred_classes = torch.max(pred_token_ids_batch, 1)\n",
    "        acc_correct += (pred_classes == target_token_ids_batch).sum().item()\n",
    "        acc_total += target_token_ids_batch.shape[0]\n",
    "        \"\"\"\n",
    "\n",
    "        if count % pbar_update_freq  == 0:\n",
    "            #iter_accuracy = 100.0 * acc_correct / acc_total\n",
    "            #pbar.set_postfix_str(f'Loss: {list_avg(avg_loss):.4f} Acc: {iter_accuracy:.2f}')\n",
    "            pbar.set_postfix_str(f'Loss: {list_avg(avg_loss):.4f}')\n",
    "            pbar.update(pbar_update_freq)\n",
    "        \n",
    "    pbar.close()\n",
    "\n",
    "    #final_accuracy = 100.0 * acc_correct / acc_total\n",
    "    #return list_avg(avg_loss), final_accuracy\n",
    "    return list_avg(avg_loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_iter_amp(dataloader, model, criterion, epoch, pbar_update_freq, device):\n",
    "    model.eval()\n",
    "    #avg_loss = 0.0\n",
    "    avg_loss = []\n",
    "    count = 0\n",
    "\n",
    "    # Accuracy\n",
    "    #acc_correct = 0\n",
    "    #acc_total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, unit=' batch', leave=False)\n",
    "    pbar.set_description(f'Epoch: {epoch}, Eval')\n",
    "    \n",
    "    for input_token_ids_batch, attention_mask_batch, target_token_ids_batch in dataloader:\n",
    "\n",
    "        input_token_ids_batch = input_token_ids_batch.to(device)\n",
    "        attention_mask_batch = attention_mask_batch.to(device)\n",
    "        target_token_ids_batch = target_token_ids_batch.to(device)\n",
    "\n",
    "        with torch.autocast(device_type=device, dtype=torch.float16, enabled=True):\n",
    "            pred_token_ids_batch = model(\n",
    "                x_input=input_token_ids_batch, \n",
    "                pad_mask=attention_mask_batch\n",
    "            )\n",
    "    \n",
    "            # Combine batch and seq_len dims together to form a \"longer batch\"\n",
    "            loss = criterion(\n",
    "                pred_token_ids_batch.view(-1, pred_token_ids_batch.size(-1)),\n",
    "                target_token_ids_batch.view(-1)\n",
    "            )\n",
    "            #loss = criterion(pred_token_ids_batch, target_token_ids_batch)\n",
    "            \n",
    "        #avg_loss += loss.item()\n",
    "        avg_loss.append(loss.item())\n",
    "        count += 1\n",
    "        \n",
    "        \"\"\"\n",
    "        _, pred_classes = torch.max(pred_token_ids_batch, 1)\n",
    "        acc_correct += (pred_classes == target_token_ids_batch).sum().item()\n",
    "        acc_total += target_token_ids_batch.shape[0]\n",
    "        \"\"\"\n",
    "\n",
    "        if count % pbar_update_freq  == 0:\n",
    "            #iter_accuracy = 100.0 * acc_correct / acc_total\n",
    "            #pbar.set_postfix_str(f'Loss: {list_avg(avg_loss):.4f} Acc: {iter_accuracy:.2f}')\n",
    "            pbar.set_postfix_str(f'Loss: {list_avg(avg_loss):.4f}')\n",
    "            pbar.update(pbar_update_freq)\n",
    "\n",
    "    pbar.close()\n",
    "    \n",
    "    #final_accuracy = 100.0 * acc_correct / acc_total\n",
    "    #return list_avg(avg_loss), final_accuracy\n",
    "    return list_avg(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f57b1e-8e6a-44d5-8dee-ca586496fc78",
   "metadata": {},
   "source": [
    "# Optimizer, Scheduler & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "869aa379-8e69-4a4e-9d24-568603099a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=hyperparameters['optimizer']['learning_rate'],\n",
    "    betas=hyperparameters['optimizer']['optimizer_betas'],\n",
    "    #weight_decay=hyperparameters['optimizer']['weight_decay']\n",
    ")\n",
    "\n",
    "# PAD ID IGNORE!!\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.token_to_id('<pad>'))\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer=optimizer,\n",
    "    mode=hyperparameters['learning_rate_sched_config']['mode'],\n",
    "    factor=hyperparameters['learning_rate_sched_config']['factor'],\n",
    "    patience=hyperparameters['learning_rate_sched_config']['patience'],\n",
    "    cooldown=hyperparameters['learning_rate_sched_config']['cooldown'],\n",
    "    min_lr=hyperparameters['learning_rate_sched_config']['min_lr'],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc063d03-4777-4ccd-a2a3-f7f0b9d3e9ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Grad Scaler (FP16) For Automatic Mixed Precision (AMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "346937c2-d889-4241-b3d8-dfa2aeb6d45b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb3f710-351d-49a5-9c1e-662a992fed5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save/Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2a627f7-8e1d-4cd8-b42e-c1a45b3c7437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, root_folder, file_name, hyperparameter_dict, metrics_dict, last_epoch, verbose=False):\n",
    "    os.makedirs(root_folder, exist_ok=True)\n",
    "    model_full_path = os.path.join(root_folder, file_name+'.pt')\n",
    "    \n",
    "    torch.save({\n",
    "        'hyperparameters': hyperparameter_dict,\n",
    "        'metrics': metrics_dict,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        #'optimizer_state_dict': optimizer.optimizer.state_dict()\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'saved_time_unix': time.time(),\n",
    "        'saved_time_asctime': time.asctime(),\n",
    "        'last_epoch': last_epoch,\n",
    "    }, model_full_path)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Model: {file_name} is saved successfully')\n",
    "    \n",
    "    \n",
    "def load_model(model, optimizer, root_folder, file_name):\n",
    "    model_full_path = os.path.join(root_folder, file_name+'.pt')\n",
    "    #checkpoint = torch.load(model_full_path, map_location='cpu')\n",
    "    checkpoint = torch.load(model_full_path)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "    \n",
    "    #if optimizer is not None:\n",
    "    #    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    print(f'Model: {file_name} is loaded successfully')\n",
    "    \n",
    "    return checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1891c-63df-4996-b67a-803fdf0d4d23",
   "metadata": {},
   "source": [
    "# Language Modelling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4fad57dc-63b2-4d74-88bd-dbcc7952df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multinomial_sampling(model, idx, max_new_tokens, max_seq_len, temp=1.0, topk=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -max_seq_len:]\n",
    "\n",
    "        logits = model(x_input=idx_cond, x_cross=None, pad_mask=None)\n",
    "        \n",
    "        \"\"\"\n",
    "        if topk is not None:\n",
    "            logits = logits.topk(topk, dim=1).values\n",
    "        \"\"\"\n",
    "        \n",
    "        logits = logits[:, -1, :]\n",
    "                   \n",
    "        if topk is not None:\n",
    "            _values, _indices = F.softmax(logits/temp, dim=-1).topk(topk, dim=1)\n",
    "            #probs = F.softmax(logits/temp, dim=-1).topk(topk, dim=-1).values\n",
    "            probs = _values\n",
    "        else:\n",
    "            probs = F.softmax(logits/temp, dim=-1)\n",
    "        \n",
    "        # sample from the distribution\n",
    "        _idx_next = torch.multinomial(probs, num_samples=1) \n",
    "        #print(_idx_next)\n",
    "        #print(_indices)\n",
    "        idx_next = _indices[:, _idx_next[0]]\n",
    "        #print(f'idx_next: {idx_next}')\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "\n",
    "\n",
    "def generate_text(model, device, n_tokens, temp, context=None, topk=None, remove_newlines=True):\n",
    "    \"\"\"\n",
    "    Assumes that model is already on \"device\"\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    if context is None:\n",
    "        #context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "        context = torch.tensor([encode('')], dtype=torch.long, device=device)\n",
    "    else:\n",
    "        context = torch.tensor([encode(context)], dtype=torch.long, device=device)\n",
    "\n",
    "    _genereted = generate_multinomial_sampling(\n",
    "            model,\n",
    "            context, \n",
    "            max_new_tokens=n_tokens, \n",
    "            max_seq_len=hyperparameters['context_size'], \n",
    "            temp=temp,\n",
    "            topk=topk\n",
    "        )\n",
    "    \n",
    "    generated = decode(\n",
    "        _genereted[0].tolist()\n",
    "    )\n",
    "    \n",
    "    if remove_newlines:\n",
    "        generated = generated.replace('\\n', '')\n",
    "        \n",
    "    print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acdf2f0-4c21-4d5c-ad42-20165fcf07e5",
   "metadata": {},
   "source": [
    "### Start Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba09dedc-b128-4b81-9299-b90a4ceae096",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a468644-449a-4f70-8668-0adb9a27abd3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Pre-Trained Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e45ff748-edfe-4fb9-82cc-5a4ecaadcde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint = load_model(model, optimizer, './saved_models', f\"{hyperparameters['model_base_name']}_best\")\n",
    "#START_EPOCH = checkpoint['last_epoch'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7608fa-b732-429c-9a00-392f766f6ee7",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92db3bf6-0923-45e2-8607-aeca5bd8e2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'best_state_dict': None,\n",
    "    'best_epoch': -1,\n",
    "    'best_val_loss': float('inf'), # TODO: val_acc can be also used\n",
    "    'best_val_acc': 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd84bcdc-ac58-4fa9-90d8-690417033759",
   "metadata": {
    "tags": [
     "train_output"
    ]
   },
   "outputs": [],
   "source": [
    "def start_training(start_epoch=1):\n",
    "    print(f'Start trainin from epoch: {start_epoch}')\n",
    "    \n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "    \n",
    "    for epoch in range(start_epoch, hyperparameters['num_epochs']+1):\n",
    "        \n",
    "        #train_loss = train_iter(\n",
    "        train_loss = train_iter_amp(\n",
    "            train_dataloader, \n",
    "            model, \n",
    "            optimizer, \n",
    "            criterion, \n",
    "            scaler, \n",
    "            epoch,\n",
    "            hyperparameters['clip_grad_norm'], \n",
    "            PBAR_UPDATE_FREQ, \n",
    "            hyperparameters['grad_accum_iter'],\n",
    "            device\n",
    "        )\n",
    "        \n",
    "        #val_loss = eval_iter(\n",
    "        val_loss = eval_iter_amp(\n",
    "            test_dataloader, \n",
    "            model, \n",
    "            criterion, \n",
    "            epoch, \n",
    "            PBAR_UPDATE_FREQ, \n",
    "            device\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        generate_text(\n",
    "            model=model, \n",
    "            device=device,\n",
    "            n_tokens=150, \n",
    "            temp=0.65, \n",
    "            context='Bu film ',\n",
    "            topk=150,\n",
    "            remove_newlines=False\n",
    "        )\n",
    "        \n",
    "        print('*'*10)\n",
    "        \n",
    "        generate_text(\n",
    "            model=model, \n",
    "            device=device,\n",
    "            n_tokens=150, \n",
    "            temp=0.85, \n",
    "            context='Bu film ',\n",
    "            topk=150,\n",
    "            remove_newlines=False\n",
    "        )\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f'Epoch: {epoch}, [LOSS] train: {train_loss:.4f}, val: {val_loss:.4f}')\n",
    "\n",
    "        \n",
    "        save_model(\n",
    "            model, \n",
    "            optimizer, \n",
    "            './saved_models', \n",
    "            f\"{hyperparameters['model_base_name']}_checkpoint\",\n",
    "            hyperparameters, \n",
    "            metrics,\n",
    "            epoch, \n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        \n",
    "        if val_loss < metrics['best_val_loss']:\n",
    "            metrics['best_state_dict'] = model.state_dict().copy()\n",
    "            metrics['best_epoch'] = epoch\n",
    "            metrics['best_val_loss'] = val_loss\n",
    "    \n",
    "            save_model(\n",
    "                model, \n",
    "                optimizer, \n",
    "                './saved_models', \n",
    "                f\"{hyperparameters['model_base_name']}_best\", \n",
    "                hyperparameters, \n",
    "                metrics,\n",
    "                epoch,\n",
    "                verbose=True\n",
    "            )\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        if val_acc > metrics['best_val_acc']:\n",
    "            metrics['best_state_dict'] = model.state_dict().copy()\n",
    "            metrics['best_epoch'] = epoch\n",
    "            metrics['best_val_acc'] = val_acc\n",
    "    \n",
    "            save_model(\n",
    "                model, \n",
    "                optimizer, \n",
    "                './saved_models', \n",
    "                'LM_Sentiment_best', \n",
    "                hyperparameters, \n",
    "                metrics,\n",
    "                epoch,\n",
    "                verbose=True\n",
    "            )\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # LR Scheduling\n",
    "        lr_scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272727c1-3c44-4307-a495-734faccc5f6b",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41227e32-437b-4acb-8462-a0a31c90e537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start trainin from epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, [LOSS] train: 8.4243, val: 8.0453\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, [LOSS] train: 7.8181, val: 7.5801\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, [LOSS] train: 7.4129, val: 7.2548\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, [LOSS] train: 7.0994, val: 7.0219\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, [LOSS] train: 6.9249, val: 6.9030\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, [LOSS] train: 6.8123, val: 6.9253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, [LOSS] train: 6.7219, val: 6.6735\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, [LOSS] train: 6.5870, val: 6.5685\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, [LOSS] train: 6.4952, val: 6.5022\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, [LOSS] train: 6.4146, val: 6.4094\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, [LOSS] train: 6.4183, val: 6.3712\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, [LOSS] train: 6.3092, val: 6.3045\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, [LOSS] train: 6.2360, val: 6.2228\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, [LOSS] train: 6.2069, val: 6.1640\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, [LOSS] train: 6.1501, val: 6.1459\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, [LOSS] train: 6.1133, val: 6.1361\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, [LOSS] train: 6.0448, val: 6.0326\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, [LOSS] train: 5.9938, val: 5.9833\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, [LOSS] train: 5.9363, val: 5.9551\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, [LOSS] train: 5.9134, val: 5.9577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, [LOSS] train: 5.8519, val: 5.8590\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, [LOSS] train: 5.8044, val: 5.8398\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, [LOSS] train: 5.7889, val: 5.7794\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, [LOSS] train: 5.7278, val: 5.7478\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, [LOSS] train: 5.8036, val: 5.7444\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, [LOSS] train: 5.6796, val: 5.6826\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, [LOSS] train: 5.8086, val: 5.7112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, [LOSS] train: 5.6327, val: 5.6471\n",
      "Model: LM_GPTSmall_Wiki_TR_best is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Train:  23%|█████████▉                                  | 360/1587 [01:31<05:11,  3.94 batch/s, Loss: 5.5870]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m start_training(start_epoch\u001b[38;5;241m=\u001b[39mSTART_EPOCH)\n",
      "Cell \u001b[0;32mIn[57], line 10\u001b[0m, in \u001b[0;36mstart_training\u001b[0;34m(start_epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m criterion\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, hyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      8\u001b[0m     \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#train_loss = train_iter(\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_iter_amp(\n\u001b[1;32m     11\u001b[0m         train_dataloader, \n\u001b[1;32m     12\u001b[0m         model, \n\u001b[1;32m     13\u001b[0m         optimizer, \n\u001b[1;32m     14\u001b[0m         criterion, \n\u001b[1;32m     15\u001b[0m         scaler, \n\u001b[1;32m     16\u001b[0m         epoch,\n\u001b[1;32m     17\u001b[0m         hyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip_grad_norm\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     18\u001b[0m         PBAR_UPDATE_FREQ, \n\u001b[1;32m     19\u001b[0m         hyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad_accum_iter\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     20\u001b[0m         device\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m#val_loss = eval_iter(\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m eval_iter_amp(\n\u001b[1;32m     25\u001b[0m         test_dataloader, \n\u001b[1;32m     26\u001b[0m         model, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m         device\n\u001b[1;32m     31\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[49], line 15\u001b[0m, in \u001b[0;36mtrain_iter_amp\u001b[0;34m(dataloader, model, optimizer, criterion, scaler, epoch, clip_grad_norm, pbar_update_freq, grad_accum_iter, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(dataloader, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m batch\u001b[39m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (input_token_ids_batch, attention_mask_batch, target_token_ids_batch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     17\u001b[0m     input_token_ids_batch \u001b[38;5;241m=\u001b[39m input_token_ids_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m     attention_mask_batch \u001b[38;5;241m=\u001b[39m attention_mask_batch\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[19], line 21\u001b[0m, in \u001b[0;36mWiki_TR.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m#sample = self.file_paths[idx]\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_paths[idx], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     22\u001b[0m         sample \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m#######################################\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m<frozen codecs>:309\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, errors)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_training(start_epoch=START_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14014a4-4399-4d93-b7e6-58ecc252f1f9",
   "metadata": {},
   "source": [
    "# Revert to Best Checkpoint (Opitional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eda804-ae22-4d94-8a7d-7f45777833d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model.load_state_dict(metrics['best_state_dict'])\n",
    "#print(f'Loaded Epoch: {metrics[\"best_epoch\"]}, with val acc: {metrics[\"best_val_loss\"]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163db7b4-3f88-48f5-b0aa-28e666bbecd0",
   "metadata": {},
   "source": [
    "# Last Save (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3165165b-2ae7-450a-9b74-cb790a5427fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save_model(\n",
    "    model, \n",
    "    optimizer, \n",
    "    './saved_models', \n",
    "    f\"{hyperparameters['model_base_name']}_latest\",\n",
    "    hyperparameters, \n",
    "    metrics,\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e7707-3da4-4d27-bc18-bc4c0884abc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cp = load_model(\n",
    "    model, \n",
    "    optimizer, \n",
    "    './saved_models', \n",
    "    f\"{hyperparameters['model_base_name']}_latest\",\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ecfba7-df70-4f8d-aec1-7e9b916f98a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae5774-9894-4245-b34f-8c0803eded0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
